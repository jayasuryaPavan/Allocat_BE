spring:
  application:
    name: allocat-erp
  profiles:
    active: dev
  datasource:
    url: ${DB_URL:jdbc:postgresql://localhost:5432/allocat_db}
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD:password}
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 10
      minimum-idle: 5
      connection-timeout: 30000
  jpa:
    hibernate:
      ddl-auto: validate
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        use_sql_comments: true
        jdbc:
          batch_size: 20
  flyway:
    enabled: true
    locations: classpath:db/migration
    baseline-on-migrate: true
  cache:
    type: simple
  mvc:
    throw-exception-if-no-handler-found: true
    async:
      request-timeout: 180000  # 3 minutes for async requests (chat API)
  web:
    resources:
      add-mappings: false

server:
  port: 8081
  servlet:
    context-path: /
  error:
    include-message: always
    include-stacktrace: on_param
  tomcat:
    connection-timeout: 180000  # 3 minutes
    threads:
      max: 200
      min-spare: 10

jwt:
  secret: ${JWT_SECRET:allocat-erp-super-secret-jwt-signing-key-minimum-256-bits-required-for-security}
  expiration: 3600000
  refresh-expiration: 604800000

app:
  file:
    upload-dir: ${UPLOAD_DIR:./uploads}
    max-file-size: 5MB

logging:
  level:
    root: INFO
    com.allocat: DEBUG
    org.springframework.web: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/allocat-erp.log
    max-size: 10MB
    max-history: 30

springdoc:
  api-docs:
    path: /v3/api-docs
  swagger-ui:
    path: /swagger-ui.html
    operationsSorter: method
    tagsSorter: alpha
    tryItOutEnabled: true

ai:
  invengadu:
    ollama-base-url: ${OLLAMA_BASE_URL:http://localhost:11434}
    ollama-model: ${OLLAMA_MODEL:llama3.2:1b}  # Using faster model - change to llama3 for better quality
    temperature: 0.7
    max-iterations: 5
    verbose: true
    timeout-seconds: 120  # 2 minutes timeout for LLM responses

